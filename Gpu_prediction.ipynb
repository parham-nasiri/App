{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+Gdc8CUuWrLTREC1bDAjJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parham-nasiri/App/blob/main/Gpu_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YsRL6gVsLtq-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/gpu_data.txt'\n",
        "\n",
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea-T_gEvQzr6",
        "outputId": "ac74566c-2676-4b92-8cd1-fbb33f2fb0c8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, \"r\") as f:\n",
        "#with open(\"gpu_data.txt\", \"r\") as f:\n",
        "  data = json.load(f)"
      ],
      "metadata": {
        "id": "Ef-4ikoeMs0n"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_data = {}\n",
        "for item in data[\"data\"][\"result\"]:\n",
        "    gpu_name = item[\"metric\"][\"gpu\"]\n",
        "    values = item[\"values\"]\n",
        "\n",
        "    for timestamp, value in values:\n",
        "        if timestamp not in gpu_data:\n",
        "            gpu_data[timestamp] = {}\n",
        "        gpu_data[timestamp][gpu_name] = float(value)\n",
        "\n",
        "\n",
        "sorted_times = sorted(gpu_data.keys())\n",
        "all_gpus = sorted({gpu for t in gpu_data.values()for gpu in t.keys()})\n",
        "\n",
        "final_vectors = []\n",
        "\n",
        "for t in sorted_times:\n",
        "    vector = [gpu_data[t].get(gpu, 0) for gpu in all_gpus]\n",
        "    final_vectors.append(vector)\n",
        "\n",
        "tensor_data = torch.tensor(final_vectors, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "CZuP4QCwU3y0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(tensor_data)\n",
        "scaled_data = torch.tensor(scaled_data, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "mf6KsbuCQx4y"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequence(data,seq_lenght):\n",
        "  X,y = [] ,[]\n",
        "  for i in range(len(data)-seq_lenght):\n",
        "    X.append(data[i:i+seq_lenght])\n",
        "    y.append(data[i+seq_lenght])\n",
        "  return torch.stack(X),torch.stack(y)\n",
        "seq_lenght = 20\n",
        "X,y = create_sequence(scaled_data,seq_lenght)"
      ],
      "metadata": {
        "id": "79VDvsqwRvDz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8*len(X))\n",
        "X_train= X[:train_size]\n",
        "y_train= y[:train_size]\n",
        "X_test= X[:train_size]\n",
        "y_test= y[:train_size]\n"
      ],
      "metadata": {
        "id": "3GGHqTpKyBdq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9NuDdNQPG26",
        "outputId": "6bfcb856-3b6e-4429-ccba-c82df8ca0e81"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1211342857.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X = torch.tensor(X, dtype=torch.float32)\n",
            "/tmp/ipython-input-1211342857.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y = torch.tensor(y, dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPUDataset(Dataset):\n",
        "  def __init__(self,X,y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.X[idx],self.y[idx]"
      ],
      "metadata": {
        "id": "r9y8sMGn3UmY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(GPUDataset(X_train, y_train),\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=False)\n",
        "\n",
        "test_loader = DataLoader(GPUDataset(X_test, y_test),\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=False)"
      ],
      "metadata": {
        "id": "I24JKBW8LeSK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_layers,num_size,dropout):\n",
        "    super().__init__()\n",
        "    self.lstm = nn.LSTM(\n",
        "        input_size=input_size,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        batch_first=True,\n",
        "        dropout=dropout\n",
        "    )\n",
        "    self.fc = nn.Linear(hidden_size,num_size)\n",
        "  def forward(self,X):\n",
        "    out, _ = self.lstm(X)\n",
        "    out = out[:, -1, :]\n",
        "    out = self.fc(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "v3RGWclaF2a4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available()else \"cpu\")\n",
        "model = LSTMModel(input_size= tensor_data.shape[1],hidden_size= 64,num_size=tensor_data.shape[1],num_layers= 2,dropout= 0.2).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "6AJxPe27Hsjn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJBPhYvaOdbh",
        "outputId": "d65c53a1-bd3d-48f0-dce4-d4b71f4b24e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6895, 20, 8])\n",
            "torch.Size([6895, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_batch)\n",
        "        loss = criterion(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"Epoch {epoch}, Train Loss: {train_loss:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQDfTepzJ6ED",
        "outputId": "f428c466-07f9-4831-8161-74afd29c9d96"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 0.047431\n",
            "Epoch 5, Train Loss: 0.019088\n",
            "Epoch 10, Train Loss: 0.008769\n",
            "Epoch 15, Train Loss: 0.004310\n",
            "Epoch 20, Train Loss: 0.003460\n",
            "Epoch 25, Train Loss: 0.003154\n",
            "Epoch 30, Train Loss: 0.002934\n",
            "Epoch 35, Train Loss: 0.002761\n",
            "Epoch 40, Train Loss: 0.002747\n",
            "Epoch 45, Train Loss: 0.002639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"gpu_lstm_model.pth\")"
      ],
      "metadata": {
        "id": "R1P9QRDHZyCt"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}